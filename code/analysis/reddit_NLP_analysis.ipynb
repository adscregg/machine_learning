{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = pd.read_csv('../../datasets/reddit_train.csv') #read in the dataset\n",
    "reddit.drop(['num', 'X'], axis = 1, inplace = True) # These columns provide no information for classification so we remove them\n",
    "reddit['REMOVED'] = reddit['REMOVED'].map({1:'Yes', 0:'No'}) # To make the understanding of the dataset clearer for now\n",
    "\n",
    "reddit.head() # see the first 5 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.describe() # stats about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.groupby('REMOVED').describe() # stats about the data group by category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit['LENGTH'] = reddit['BODY'].apply(len) # find the length of each comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.hist(column = 'LENGTH', bins = 100, by = 'REMOVED', sharex = True, figsize = (13,5)) # histogram of num of characters in each comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we can see that the length of the comment does not seem to be a good indicator of whether a message was removed or not, this is as expected but it is always worth exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_punc(text):\n",
    "    punc = [char for char in text if char in string.punctuation] # add punctuation to list\n",
    "    return len(punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit['NUM_PUNC'] = reddit['BODY'].apply(extract_punc) # apply above function to each row of data\n",
    "reddit.hist(column = 'NUM_PUNC', bins = 100, by = 'REMOVED', sharex = True, figsize = (13,5)) # histogram of num of punctuation marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again this shows that there is little to no difference between the distribution of number of punctuation points used in comments that were removed and not removed meaning it is not a good indicator to add to our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data\n",
    "\n",
    "It is important to preprocess your text data into a simpler form, for example removed words that carry no weight, e.g. 'I' or 'an' so as to not drown out the important words that do carry meaning, we will also remove punctuation from our comments, however this could be an important feature in some datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    no_punc = [char for char in text if char not in string.punctuation] # non punctuation characters\n",
    "    no_punc = ''.join(no_punc) # join back together to a single string\n",
    "    return [word for word in no_punc.split() if word.lower() not in stopwords.words('english')] # remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reddit['BODY'], reddit['REMOVED']) # split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = Pipeline([('bow', CountVectorizer(analyzer=text_process)), # create pipline\n",
    "                            ('tfidf', TfidfTransformer()), # Term Frequency Inverse Document Frequency\n",
    "                            ('NaiveBayes', MultinomialNB()) # NaiveBayes algorithm\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, test  and adapt models\n",
    "Note: These models may take a while to train, particularly on a slow computer or laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_analysis = text_pipeline.fit(X_train, y_train) # run the pipeline\n",
    "pred = remove_analysis.predict(X_test) # predict values based on model\n",
    "\n",
    "print(accuracy_score(y_test, pred), '\\n\\n')\n",
    "print(classification_report(y_test, pred), '\\n\\n')\n",
    "print(confusion_matrix(y_test, pred), '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that although the accuracy score of this model seemed decent at around 68%, the actual model is terrible, this could be due to the significant class imbalance. Following, we create a model where the classes are evenly balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_no = reddit[reddit['REMOVED'] == 'No'] # data from the No class\n",
    "reddit_yes = reddit[reddit['REMOVED'] == 'Yes'] # data from the Yes class\n",
    "to_select = min(len(reddit_no), len(reddit_yes)) # length of smallest dataset\n",
    "\n",
    "reddit = pd.concat([reddit_no.iloc[:to_select,:], reddit_yes.iloc[:to_select,:]]) # combine the datasets so they are balanced\n",
    "\n",
    "\n",
    "sns.countplot(reddit['REMOVED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reddit['BODY'], reddit['REMOVED']) # split training data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_analysis_balanced = text_pipeline.fit(X_train, y_train) # fit pipeline\n",
    "pred_balanced = remove_analysis_balanced.predict(X_test) # predict values\n",
    "\n",
    "print(accuracy_score(y_test, pred_balanced), '\\n\\n')\n",
    "print(classification_report(y_test, pred_balanced), '\\n\\n')\n",
    "print(confusion_matrix(y_test, pred_balanced), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Although the accuracy of the model is approximitely equal to that of the previous one, the overall performance metrics are much better as the model predicts more evenly about the classes. This is demonstrative as to why you need to explore your data before blindly fitting a model to it and looking at only the accuracy score as this can paint a very false picture of how good your model is. The phrase 'Garbage in garbage out comes to mind here'.\n",
    "\n",
    "To make the predictions better, another thing that might work is stemming. This is the process of attempting to reduce a word down to it's base word, e.g. running would become run. Lets try this and see if it has an impact on our predictions.(we will use the same balanced dataset as the previous model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process_with_stem(text):\n",
    "    ps = PorterStemmer() # stemmer object\n",
    "    no_punc = [char for char in text if char not in string.punctuation] # remove punctuation\n",
    "    no_punc = ''.join(no_punc) # combine to a string\n",
    "    no_stops = [word for word in no_punc.split() if word.lower() not in stopwords.words('english')] # remove stopwords\n",
    "    words_ps = [ps.stem(word.lower()) for word in no_stops] # stem words\n",
    "    return words_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline_stem = Pipeline([('bow', CountVectorizer(analyzer=text_process_with_stem)), # changed analyzer\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('NaiveBayes', MultinomialNB())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reddit['BODY'], reddit['REMOVED']) # split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_analysis_balanced_stem = text_pipeline_stem.fit(X_train, y_train) # fit model\n",
    "pred_balanced_stem = remove_analysis_balanced_stem.predict(X_test) # predict off of model\n",
    "\n",
    "print(accuracy_score(y_test, pred_balanced_stem), '\\n\\n')\n",
    "print(classification_report(y_test, pred_balanced_stem), '\\n\\n')\n",
    "print(confusion_matrix(y_test, pred_balanced_stem), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs very simmilar to the previous model, it is possibly marginally better but this will likely depend on how the data is split. Instead of stemming, we could try Lemmatizing the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process_with_lemma(text):\n",
    "    lemma = WordNetLemmatizer()\n",
    "    no_punc = [char for char in text if char not in string.punctuation]\n",
    "    no_punc = ''.join(no_punc)\n",
    "    no_stops = [word for word in no_punc.split() if word.lower() not in stopwords.words('english')]\n",
    "    words_lemma = [lemma.lemmatize(word.lower()) for word in no_stops] # Lemmatize words\n",
    "    return words_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline_lemma = Pipeline([('bow', CountVectorizer(analyzer=text_process_with_lemma)), # changed analyzer\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('NaiveBayes', MultinomialNB())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reddit['BODY'], reddit['REMOVED']) # split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_analysis_balanced_lemma = text_pipeline_lemma.fit(X_train, y_train) # fit model\n",
    "pred_balanced_lemma = remove_analysis_balanced_lemma.predict(X_test) # predict unseen instances\n",
    "\n",
    "print(accuracy_score(y_test, pred_balanced_stem), '\\n\\n')\n",
    "print(classification_report(y_test, pred_balanced_stem), '\\n\\n')\n",
    "print(confusion_matrix(y_test, pred_balanced_stem), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model appears to be no better than chance at predicting whether a comment should be removed, therefore we abandon this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
